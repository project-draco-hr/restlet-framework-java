def test_main():
    if verbose:
        print 'starting...'
    f = open(findfile((('tokenize_tests' + os.extsep) + 'txt')))
    tokenize(f.readline)
    f.close()
    f = findfile((('tokenize_tests' + os.extsep) + 'txt'))
    test_roundtrip(f)
    testdir = (os.path.dirname(f) or os.curdir)
    testfiles = glob.glob(((testdir + os.sep) + 'test*.py'))
    if (not is_resource_enabled('compiler')):
        testfiles = random.sample(testfiles, 10)
    for f in testfiles:
        test_roundtrip(f)
    sampleBadText = 'def foo():\n    bar\n  baz\n'
    try:
        for tok in generate_tokens(StringIO(sampleBadText).readline):
            pass
    except IndentationError:
        pass
    else:
        raise TestFailed('Did not detect IndentationError:')
    from test import test_tokenize
    from test.test_support import run_doctest
    run_doctest(test_tokenize)
    if verbose:
        print 'finished'
